{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b537c0-5308-494e-b479-df1ed1fd34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transf\n",
    "from data_feed import DataFeed, DataFeed_image_pos\n",
    "from build_net import resnet50, NN_beam_pred, MultinomialLogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa17e9f-2958-489b-af3e-4dab1dfe1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# or full reproducibility\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38bfa9a-c6ef-450a-9180-61eb294a2ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Now you can use the `device` variable to move your model and data to the correct device\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be724f96-0c63-47c8-ad68-1b617c05d244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Overview:\n",
      "   index_x  unit2_lat  unit2_lon  unit2_height  unit2_distance  \\\n",
      "0     9862   0.188929   0.431909      1.000000        0.167641   \n",
      "1     4449   0.410610   0.286188      0.231752        0.361212   \n",
      "2    10299   0.365071   0.424029      0.174270        0.246799   \n",
      "3     9229   0.335884   0.431909      0.656934        0.210932   \n",
      "4     6947   0.175857   0.390571      0.056569        0.242568   \n",
      "\n",
      "                                           unit1_rgb  unit1_beam_x  \\\n",
      "0  ./../Carla/datasets/scenario23_dev//unit1/came...            17   \n",
      "1  ./../Carla/datasets/scenario23_dev//unit1/came...            14   \n",
      "2  ./../Carla/datasets/scenario23_dev//unit1/came...            20   \n",
      "3  ./../Carla/datasets/scenario23_dev//unit1/came...            17   \n",
      "4  ./../Carla/datasets/scenario23_dev//unit1/came...            14   \n",
      "\n",
      "   lat_region  lon_region  region  \n",
      "0           0           1       1  \n",
      "1           1           0       2  \n",
      "2           1           1       3  \n",
      "3           1           1       3  \n",
      "4           0           0       0  \n",
      "\n",
      "Data Summary:\n",
      "            index_x   unit2_lat   unit2_lon  unit2_height  unit2_distance  \\\n",
      "count    570.000000  570.000000  570.000000    570.000000      570.000000   \n",
      "mean    5765.140351    0.339799    0.404146      0.326157        0.276529   \n",
      "std     3235.268614    0.154570    0.105268      0.267289        0.152336   \n",
      "min       20.000000    0.030779    0.081985      0.017336        0.001901   \n",
      "25%     3018.500000    0.226024    0.352309      0.092153        0.173065   \n",
      "50%     5894.500000    0.306971    0.412554      0.208029        0.231712   \n",
      "75%     8530.500000    0.399213    0.451542      0.552007        0.357941   \n",
      "max    11349.000000    0.981461    0.845154      1.000000        0.920808   \n",
      "\n",
      "       unit1_beam_x  lat_region  lon_region      region  \n",
      "count    570.000000  570.000000  570.000000  570.000000  \n",
      "mean      15.608772    0.492982    0.524561    1.510526  \n",
      "std        4.621672    0.500390    0.499835    1.181608  \n",
      "min        2.000000    0.000000    0.000000    0.000000  \n",
      "25%       14.000000    0.000000    0.000000    0.000000  \n",
      "50%       16.000000    0.000000    1.000000    1.000000  \n",
      "75%       17.000000    1.000000    1.000000    3.000000  \n",
      "max       30.000000    1.000000    1.000000    3.000000  \n",
      "\n",
      "Missing Values:\n",
      "index_x           0\n",
      "unit2_lat         0\n",
      "unit2_lon         0\n",
      "unit2_height      0\n",
      "unit2_distance    0\n",
      "unit1_rgb         0\n",
      "unit1_beam_x      0\n",
      "lat_region        0\n",
      "lon_region        0\n",
      "region            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the saved CSV files\n",
    "output_dir = \"./feature_IID/\"\n",
    "\n",
    "# Load one of the CSV files for EDA (e.g., user_0_outputs.csv)\n",
    "df = pd.read_csv(output_dir + \"user_0_pos_height_beam.csv\")\n",
    "\n",
    "# Quick overview of the data\n",
    "print(\"Data Overview:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43bf9b52-16e1-4ec8-acd5-1cbd19cab71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All loadred are loaded\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "########################### Data pre-processing ########################\n",
    "########################################################################\n",
    "from torch.utils.data import ConcatDataset\n",
    "no_users = 1\n",
    "all_datasets_splits = 20\n",
    "batch_size = 64\n",
    "img_resize = transf.Resize((224, 224))\n",
    "img_norm = transf.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "proc_pipe = transf.Compose(\n",
    "    [transf.ToPILImage(),\n",
    "     img_resize,\n",
    "     transf.ToTensor(),\n",
    "     img_norm]\n",
    ")\n",
    "dataset_dir = \"feature_IID/\"\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "val_loaders = []\n",
    "train_combined_dataset = []\n",
    "val_combined_datasets = []\n",
    "for user_id in range(all_datasets_splits):\n",
    "    train_dir = dataset_dir + f'user_{user_id}_pos_height_beam_train.csv'\n",
    "    val_dir = dataset_dir + f'user_{user_id}_pos_height_beam_val.csv'\n",
    "    test_dir = dataset_dir + f'user_{user_id}_pos_height_beam_test.csv'\n",
    "    \n",
    "    train_dataset = DataFeed_image_pos(train_dir, transform=proc_pipe)\n",
    "    val_dataset = DataFeed_image_pos(root_dir=val_dir, transform=proc_pipe)\n",
    "    test_dataset = DataFeed_image_pos(root_dir=test_dir, transform=proc_pipe)\n",
    "    train_combined_dataset.append(train_dataset)\n",
    "    val_combined_datasets.append(val_dataset)\n",
    "\n",
    "train_dataset = ConcatDataset(train_combined_dataset)\n",
    "val_dataset = ConcatDataset(val_combined_datasets)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              #num_workers=8,\n",
    "                              shuffle=False)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        #num_workers=8,\n",
    "                        shuffle=False)\n",
    "\n",
    "print(\"All loadred are loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2aeb40-49ab-4536-a119-acf212a41a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Preperation#\n",
    "all_models = []\n",
    "available_modalities = [\"pos_height\", \"images\"]\n",
    "modality_size = {\"pos_height\": 128, \"images\": 128}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5627ec-2bc5-406a-bed8-a058e4a728b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Groups: [1, 2, 3]\n",
      "User Modalities: [['pos_height'], ['images'], ['pos_height', 'images']]\n",
      "Output Sizes: [128, 128, 256]\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "import random\n",
    "no_users = 3  # Example: Number of users\n",
    "available_modalities = [\"pos_height\", \"images\"]\n",
    "modality_size = {\"pos_height\": 128, \"images\": 128}\n",
    "group_definitions = {\n",
    "    1: [\"pos_height\"],        # Group 1: Only pos_height\n",
    "    2: [\"images\"],            # Group 2: Only images\n",
    "    3: [\"pos_height\", \"images\"]  # Group 3: Both modalities\n",
    "}\n",
    "\n",
    "# Assign each user to a group randomly\n",
    "weights = [0.2, 0.3, 0.5]  # Probabilities for groups 1, 2, and 3\n",
    "\n",
    "# Generate user_groups with weighted random choices\n",
    "user_groups = [1, 2, 3] #random.choices([1, 2, 3], weights=weights, k=no_users)\n",
    "\n",
    "# Assign modalities to users based on their group\n",
    "user_modalities = [group_definitions[group] for group in user_groups]\n",
    "\n",
    "# Compute output sizes for each user based on their modalities\n",
    "output_sizes = [sum(modality_size[modality] for modality in user_modality) for user_modality in user_modalities]\n",
    "\n",
    "# Store models (placeholders for actual models)\n",
    "all_models = []\n",
    "\n",
    "# Example output (for verification)\n",
    "print(f\"User Groups: {user_groups[:10]}\")  # Show first 10 users' groups\n",
    "print(f\"User Modalities: {user_modalities[:10]}\")  # Show first 10 users' modalities\n",
    "print(f\"Output Sizes: {output_sizes[:10]}\")  # Show first 10 users' output sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ed4d5c-f244-40b5-9036-25a31edc6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_knopp(matrix, tol=1e-9, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Converts a given matrix to a doubly stochastic matrix using the Sinkhorn-Knopp algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "        matrix (np.ndarray): The input matrix to be transformed.\n",
    "        tol (float): The tolerance for convergence.\n",
    "        max_iter (int): Maximum number of iterations for convergence.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A doubly stochastic matrix.\n",
    "    \"\"\"\n",
    "    matrix = matrix.copy()\n",
    "    for _ in range(max_iter):\n",
    "        # Normalize rows\n",
    "        row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "        matrix /= row_sums\n",
    "\n",
    "        # Normalize columns\n",
    "        col_sums = matrix.sum(axis=0, keepdims=True)\n",
    "        matrix /= col_sums\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.allclose(matrix.sum(axis=1), 1, atol=tol) and np.allclose(matrix.sum(axis=0), 1, atol=tol):\n",
    "            break\n",
    "\n",
    "    return matrix\n",
    "    \n",
    "def create_random_topology(num_users, similarity_matrix, edge_probability=0.3):\n",
    "    \"\"\"\n",
    "    Creates a connected random topology using NetworkX.\n",
    "    Returns the adjacency matrix.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        graph = nx.erdos_renyi_graph(num_users, edge_probability)\n",
    "        adjacency_matrix = nx.to_numpy_array(graph)\n",
    "        new_adj = np.multiply(adjacency_matrix, similarity_matrix)\n",
    "        new_graph = nx.from_numpy_array(new_adj)\n",
    "        if nx.is_connected(new_graph):\n",
    "            break\n",
    "\n",
    "    # Convert graph to adjacency matrix\n",
    "    adjacency_matrix = nx.to_numpy_array(new_graph)\n",
    "    return adjacency_matrix\n",
    "\n",
    "def prepare_mixing_matrices(adjacency_matrix, similarity_matrices):\n",
    "    \"\"\"\n",
    "    Computes a mixing matrix for each modality by multiplying the adjacency matrix \n",
    "    with the similarity matrix for that modality.\n",
    "    Returns a dictionary of mixing matrices.\n",
    "    \"\"\"\n",
    "    adjacency_matrices = {}\n",
    "    mixing_matrices = {}\n",
    "    for modality, similarity_matrix in similarity_matrices.items():\n",
    "        # Element-wise multiplication of adjacency and similarity matrices\n",
    "        combined_matrix = adjacency_matrix * similarity_matrix\n",
    "        adjacency_matrices[modality] = combined_matrix\n",
    "        \n",
    "        # Normalize to create a doubly matrix\n",
    "        mixing_matrix = sinkhorn_knopp(combined_matrix)\n",
    "        \n",
    "        \n",
    "        mixing_matrices[modality] = mixing_matrix\n",
    "    \n",
    "    return mixing_matrices, adjacency_matrices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e64903e-aade-4ec3-b367-87a0a339a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Network\n",
    "class ImageNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageNet, self).__init__()\n",
    "        self.feature_extractor = resnet50(pretrained=True, progress=True, num_classes=64)  # ResNet50 for image input\n",
    "        self.bn = nn.BatchNorm1d(128)  # Batch Normalization for image stream\n",
    "        self.fc = MultinomialLogisticRegression(input_size=128, num_classes=64)  # Adjust input_size & num_classes\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Position Network\n",
    "class PosNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PosNet, self).__init__()\n",
    "        self.feature_extractor = NN_beam_pred(num_features=4, num_output=64)  # Neural network for position input\n",
    "        self.bn = nn.BatchNorm1d(128)  # Batch Normalization for position stream\n",
    "        self.fc = MultinomialLogisticRegression(input_size=128, num_classes=64)  # Adjust input_size & num_classes\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca511b8-585b-4698-a6bc-bfb3ab69ea83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer dim = 64\n",
      "<class 'build_net.Bottleneck'>\n",
      "Output layer dim = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.9/tarfile.py:2239: RuntimeWarning: The default behavior of tarfile extraction has been changed to disallow common exploits (including CVE-2007-4559). By default, absolute/parent paths are disallowed and some mode bits are cleared. See https://access.redhat.com/articles/7004769 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'build_net.Bottleneck'>\n",
      "Output layer dim = 64\n",
      "<class 'build_net.Bottleneck'>\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "optimizers = []\n",
    "for user_id in range(no_users):\n",
    "    user_model = {}\n",
    "    local_optimizer = {}\n",
    "    if \"images\" in user_modalities[user_id]:\n",
    "        user_model[\"images\"] = ImageNet().to(device)\n",
    "        #user_model[\"images\"] = resnet50(pretrained=True, progress=True, num_classes=64)\n",
    "        local_optimizer[\"images\"] = optim.Adam(user_model[\"images\"].parameters(), lr=lr)\n",
    "    if \"pos_height\" in user_modalities[user_id]:\n",
    "        user_model[\"pos_height\"] = PosNet().to(device)\n",
    "        #user_model[\"pos_height\"] = NN_beam_pred(num_features=4, num_output=64)\n",
    "        local_optimizer[\"pos_height\"] = optim.Adam(user_model[\"pos_height\"].parameters(), lr=lr)\n",
    "    all_models.append(user_model)\n",
    "    optimizers.append(local_optimizer)\n",
    "base_models = {\"images\": ImageNet().to(device), \"pos_height\": PosNet().to(device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f56ccd1e-5893-492e-aaf8-7406a37793fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Decentralized aggregation function\n",
    "def decentralized_aggregation(user_models, mixing_matrices, available_modalities):\n",
    "    num_users = len(user_models)\n",
    "    \n",
    "    for modality in available_modalities:\n",
    "        # Get the mixing matrix for the current modality\n",
    "        mixing_matrix = mixing_matrices[modality]\n",
    "        \n",
    "        # Convert user model parameters to vectors for aggregation\n",
    "        aggregated_models = []\n",
    "        aggregated_updates = []\n",
    "        for user_model in user_models:\n",
    "            if modality in user_model.keys(): \n",
    "                aggregated_models.append(torch.nn.utils.parameters_to_vector(user_model[modality].parameters()))\n",
    "                aggregated_updates.append(torch.zeros_like(aggregated_models[-1]))\n",
    "            else:\n",
    "                aggregated_models.append(0)\n",
    "                aggregated_updates.append(0)\n",
    "        \n",
    "        \n",
    "        # Perform model aggregation based on the mixing matrix for this modality\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_users):\n",
    "                if mixing_matrix[i, j] > 0:\n",
    "                    aggregated_updates[i] += mixing_matrix[i, j] * aggregated_models[j]\n",
    "        \n",
    "        # Update user models with aggregated parameters for the current modality\n",
    "        for i in range(num_users):\n",
    "            if modality in user_models[i].keys():\n",
    "                torch.nn.utils.vector_to_parameters(aggregated_updates[i], user_models[i][modality].parameters())\n",
    "\n",
    "\n",
    "def train_local_model(local_modalities, models, train_loader, criterion, optimizers, epochs):\n",
    "\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "\n",
    "    max_acc = 0\n",
    "    max_loss = 0\n",
    "\n",
    "    for modality in local_modalities:\n",
    "        #print(f\"Training for modality: {modality}\")\n",
    "\n",
    "        model = models[modality]\n",
    "        optimizer = optimizers[modality]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()  # Set model to training mode\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            for data_batch, labels in train_loader:\n",
    "                # Get the data for the current modality\n",
    "                data = data_batch[modality]\n",
    "                \n",
    "\n",
    "                # Move data to GPU if available\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(data)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update loss and accuracy metrics\n",
    "                epoch_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "            # Calculate average loss and accuracy for the epoch\n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            accuracy = correct_predictions / total_samples\n",
    "\n",
    "            # Store metrics for debugging\n",
    "            training_losses.append(avg_loss)\n",
    "            training_accuracies.append(accuracy)\n",
    "\n",
    "            #print(\n",
    "            #    f\"Epoch [{epoch + 1}/{epochs}], Modality: {modality}, \"\n",
    "            #    f\"Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\"\n",
    "            #)\n",
    "\n",
    "    return min(training_losses), max(training_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1283f587-3182-4141-9c59-7123ee545153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_user_models(user_id, user_models, val_loaders, criterion):\n",
    "\n",
    "    total_acc = []\n",
    "    total_los = []\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for modality, model in user_models.items():\n",
    "            total_loss = 0.0\n",
    "            total_correct = 0\n",
    "            total_samples = 0\n",
    "            model.eval()\n",
    "            if modality not in user_models.keys():\n",
    "                print(f\"Skipping modality {modality} for User {user_id + 1}, no validation data.\")\n",
    "                continue\n",
    "            \n",
    "            for data, labels in val_loaders:  # Iterate over validation data for the modality\n",
    "                data = data[modality]\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Accumulate loss and accuracy\n",
    "                total_loss += loss.item() * labels.size(0)  # Sum loss for the batch\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_correct += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "            # Compute metrics\n",
    "            avg_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "            accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "            total_acc.append(accuracy)\n",
    "            total_los.append(avg_loss)\n",
    "        \n",
    "            #print(f\"User {user_id + 1}, modality: {modality} - Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        return {'loss': min(total_los), 'accuracy': max(total_acc)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c9171-1ac2-49ec-bb29-eecec3a3c260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Round 1\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 2.3719, Train Accuracy: 0.4025\n",
      "  Group 1 - Val Loss: 1.5400, Val Accuracy: 0.5050\n",
      "  Group 2 - Train Loss: 1.0727, Train Accuracy: 0.7325\n",
      "  Group 2 - Val Loss: 0.6980, Val Accuracy: 0.7886\n",
      "  Group 3 - Train Loss: 1.1032, Train Accuracy: 0.7337\n",
      "  Group 3 - Val Loss: 0.6236, Val Accuracy: 0.8073\n",
      "Global Round 2\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 1.3381, Train Accuracy: 0.5447\n",
      "  Group 1 - Val Loss: 1.3045, Val Accuracy: 0.5500\n",
      "  Group 2 - Train Loss: 0.5073, Train Accuracy: 0.8377\n",
      "  Group 2 - Val Loss: 0.5242, Val Accuracy: 0.8132\n",
      "  Group 3 - Train Loss: 0.5107, Train Accuracy: 0.8412\n",
      "  Group 3 - Val Loss: 0.4783, Val Accuracy: 0.8371\n",
      "Global Round 3\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 1.2003, Train Accuracy: 0.5745\n",
      "  Group 1 - Val Loss: 1.2159, Val Accuracy: 0.5675\n",
      "  Group 2 - Train Loss: 0.4378, Train Accuracy: 0.8496\n",
      "  Group 2 - Val Loss: 0.4402, Val Accuracy: 0.8439\n",
      "  Group 3 - Train Loss: 0.4408, Train Accuracy: 0.8506\n",
      "  Group 3 - Val Loss: 0.4636, Val Accuracy: 0.8447\n",
      "Global Round 4\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 1.1292, Train Accuracy: 0.5953\n",
      "  Group 1 - Val Loss: 1.3603, Val Accuracy: 0.5056\n",
      "  Group 2 - Train Loss: 0.4035, Train Accuracy: 0.8610\n",
      "  Group 2 - Val Loss: 0.4666, Val Accuracy: 0.8424\n",
      "  Group 3 - Train Loss: 0.4072, Train Accuracy: 0.8613\n",
      "  Group 3 - Val Loss: 0.4506, Val Accuracy: 0.8327\n",
      "Global Round 5\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 1.0772, Train Accuracy: 0.6073\n",
      "  Group 1 - Val Loss: 1.0761, Val Accuracy: 0.6102\n",
      "  Group 2 - Train Loss: 0.3882, Train Accuracy: 0.8620\n",
      "  Group 2 - Val Loss: 0.4991, Val Accuracy: 0.8193\n",
      "  Group 3 - Train Loss: 0.3833, Train Accuracy: 0.8644\n",
      "  Group 3 - Val Loss: 0.4445, Val Accuracy: 0.8380\n",
      "Global Round 6\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 1.0485, Train Accuracy: 0.6117\n",
      "  Group 1 - Val Loss: 1.2990, Val Accuracy: 0.5292\n",
      "  Group 2 - Train Loss: 0.3635, Train Accuracy: 0.8705\n",
      "  Group 2 - Val Loss: 0.5776, Val Accuracy: 0.7611\n",
      "  Group 3 - Train Loss: 0.3612, Train Accuracy: 0.8692\n",
      "  Group 3 - Val Loss: 0.4387, Val Accuracy: 0.8471\n",
      "Global Round 7\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 1.0160, Train Accuracy: 0.6247\n",
      "  Group 1 - Val Loss: 1.0712, Val Accuracy: 0.6102\n",
      "  Group 2 - Train Loss: 0.3470, Train Accuracy: 0.8753\n",
      "  Group 2 - Val Loss: 0.4845, Val Accuracy: 0.8330\n",
      "  Group 3 - Train Loss: 0.3475, Train Accuracy: 0.8755\n",
      "  Group 3 - Val Loss: 0.4419, Val Accuracy: 0.8409\n",
      "Global Round 8\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 0.9935, Train Accuracy: 0.6306\n",
      "  Group 1 - Val Loss: 1.2241, Val Accuracy: 0.5348\n",
      "  Group 2 - Train Loss: 0.3418, Train Accuracy: 0.8753\n",
      "  Group 2 - Val Loss: 0.4672, Val Accuracy: 0.8386\n",
      "  Group 3 - Train Loss: 0.3323, Train Accuracy: 0.8794\n",
      "  Group 3 - Val Loss: 0.4526, Val Accuracy: 0.8406\n",
      "Global Round 9\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 0.9780, Train Accuracy: 0.6359\n",
      "  Group 1 - Val Loss: 1.0005, Val Accuracy: 0.6348\n",
      "  Group 2 - Train Loss: 0.2977, Train Accuracy: 0.8929\n",
      "  Group 2 - Val Loss: 0.4724, Val Accuracy: 0.8374\n",
      "  Group 3 - Train Loss: 0.3180, Train Accuracy: 0.8852\n",
      "  Group 3 - Val Loss: 0.4654, Val Accuracy: 0.8363\n",
      "Global Round 10\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 0.9651, Train Accuracy: 0.6391\n",
      "  Group 1 - Val Loss: 1.0297, Val Accuracy: 0.6070\n",
      "  Group 2 - Train Loss: 0.2670, Train Accuracy: 0.9051\n",
      "  Group 2 - Val Loss: 0.5139, Val Accuracy: 0.8313\n",
      "  Group 3 - Train Loss: 0.3049, Train Accuracy: 0.8888\n",
      "  Group 3 - Val Loss: 0.5886, Val Accuracy: 0.8140\n",
      "Global Round 11\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 0.9544, Train Accuracy: 0.6417\n",
      "  Group 1 - Val Loss: 0.9550, Val Accuracy: 0.6404\n",
      "  Group 2 - Train Loss: 0.2618, Train Accuracy: 0.9039\n",
      "  Group 2 - Val Loss: 0.5023, Val Accuracy: 0.8357\n",
      "  Group 3 - Train Loss: 0.3335, Train Accuracy: 0.8778\n",
      "  Group 3 - Val Loss: 0.4892, Val Accuracy: 0.8310\n",
      "Global Round 12\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 0.9462, Train Accuracy: 0.6405\n",
      "  Group 1 - Val Loss: 0.9611, Val Accuracy: 0.6257\n",
      "  Group 2 - Train Loss: 0.2466, Train Accuracy: 0.9101\n",
      "  Group 2 - Val Loss: 0.5379, Val Accuracy: 0.8442\n",
      "  Group 3 - Train Loss: 0.2900, Train Accuracy: 0.8900\n",
      "  Group 3 - Val Loss: 0.5478, Val Accuracy: 0.8319\n",
      "Global Round 13\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 0.9367, Train Accuracy: 0.6454\n",
      "  Group 1 - Val Loss: 0.9110, Val Accuracy: 0.6632\n",
      "  Group 2 - Train Loss: 0.2494, Train Accuracy: 0.9071\n",
      "  Group 2 - Val Loss: 0.5505, Val Accuracy: 0.8424\n",
      "  Group 3 - Train Loss: 0.2646, Train Accuracy: 0.8985\n",
      "  Group 3 - Val Loss: 0.5487, Val Accuracy: 0.8254\n",
      "Global Round 14\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 0.9274, Train Accuracy: 0.6479\n",
      "  Group 1 - Val Loss: 1.0052, Val Accuracy: 0.6295\n",
      "  Group 2 - Train Loss: 0.2430, Train Accuracy: 0.9118\n",
      "  Group 2 - Val Loss: 0.5947, Val Accuracy: 0.8304\n",
      "  Group 3 - Train Loss: 0.2415, Train Accuracy: 0.9048\n",
      "  Group 3 - Val Loss: 0.5307, Val Accuracy: 0.8389\n",
      "Global Round 15\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 0.9211, Train Accuracy: 0.6527\n",
      "  Group 1 - Val Loss: 0.9181, Val Accuracy: 0.6556\n",
      "  Group 2 - Train Loss: 0.2221, Train Accuracy: 0.9194\n",
      "  Group 2 - Val Loss: 0.5781, Val Accuracy: 0.8354\n",
      "  Group 3 - Train Loss: 0.2268, Train Accuracy: 0.9126\n",
      "  Group 3 - Val Loss: 0.5445, Val Accuracy: 0.8287\n",
      "Global Round 16\n",
      "0\n",
      "1\n",
      "2\n",
      "20] Group Metrics:\n",
      "  Group 1 - Train Loss: 0.9123, Train Accuracy: 0.6543\n",
      "  Group 1 - Val Loss: 0.8942, Val Accuracy: 0.6757\n",
      "  Group 2 - Train Loss: 0.1869, Train Accuracy: 0.9301\n",
      "  Group 2 - Val Loss: 0.6210, Val Accuracy: 0.8325\n",
      "  Group 3 - Train Loss: 0.2121, Train Accuracy: 0.9203\n",
      "  Group 3 - Val Loss: 0.5519, Val Accuracy: 0.8325\n",
      "Global Round 17\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "lambda_reg = 0.01\n",
    "eta = 0.01\n",
    "\n",
    "# Dictionaries to store metrics\n",
    "group_train_loss_histories = {1: [], 2: [], 3: []}\n",
    "group_train_accuracy_histories = {1: [], 2: [], 3: []}\n",
    "group_val_loss_histories = {1: [], 2: [], 3: []}\n",
    "group_val_accuracy_histories = {1: [], 2: [], 3: []}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "global_rounds = 20\n",
    "local_epochs = 1\n",
    "# Decentralized Federated Learning Loop\n",
    "for round_num in range(global_rounds):\n",
    "\n",
    "    # Decentralized aggregation\n",
    "    #decentralized_aggregation(all_models, mixing_matrices, available_modalities)\n",
    "    epoch_group_train_losses = {1: [], 2: [], 3: []}\n",
    "    epoch_group_train_accuracies = {1: [], 2: [], 3: []}\n",
    "    epoch_group_val_losses = {1: [], 2: [], 3: []}\n",
    "    epoch_group_val_accuracies = {1: [], 2: [], 3: []}\n",
    "\n",
    "    \n",
    "    print(f\"Global Round {round_num + 1}\")\n",
    "\n",
    "    # Training for image modalities\n",
    "    \n",
    "    epoch_train_loss = 0.0\n",
    "    correct_train_predictions = 0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for user_id in range(no_users):\n",
    "        #print(f\"Training model for User {user_id + 1}\")\n",
    "        print(user_id)\n",
    "        user_models = all_models[user_id]\n",
    "        group = user_groups[user_id]\n",
    "        \n",
    "        # Initialize optimizers for each modality\n",
    "        \n",
    "        # Train local model\n",
    "        train_losses, train_accuracies = train_local_model(\n",
    "            user_modalities[user_id],\n",
    "            user_models,\n",
    "            train_loader,\n",
    "            criterion,\n",
    "            optimizers[user_id],\n",
    "            local_epochs\n",
    "        )\n",
    "        epoch_group_train_losses[group].append(train_losses)\n",
    "        epoch_group_train_accuracies[group].append(train_accuracies)\n",
    "\n",
    "        # Assign metrics to the respective group\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    # Validation phase\n",
    "    \n",
    "    for user_id in range(no_users):\n",
    "        user_models = all_models[user_id]\n",
    "        val_dict = validate_user_models(\n",
    "            user_id,\n",
    "            user_models,\n",
    "            val_loader,\n",
    "            criterion\n",
    "        )\n",
    "        group = user_groups[user_id]\n",
    "        epoch_group_val_losses[group].append(val_dict[\"loss\"])\n",
    "        epoch_group_val_accuracies[group].append(val_dict[\"accuracy\"])\n",
    "\n",
    "    # Print group-wise metrics\n",
    "    #print(f\"Metrics for Global Round {round_num + 1}:\")\n",
    "    for group in [1, 2, 3]:\n",
    "\n",
    "        group_train_loss_histories[group].append(epoch_group_train_losses[group])\n",
    "        group_train_accuracy_histories[group].append(epoch_group_train_accuracies[group])\n",
    "        group_val_loss_histories[group].append(epoch_group_val_losses[group])\n",
    "        group_val_accuracy_histories[group].append(epoch_group_val_accuracies[group])\n",
    "\n",
    "    print(f\"{global_rounds}] Group Metrics:\")\n",
    "    for group in [1, 2, 3]:\n",
    "        print(f\"  Group {group} - Train Loss: {np.mean(group_train_loss_histories[group][-1]):.4f}, Train Accuracy: {np.mean(group_train_accuracy_histories[group][-1]):.4f}\")\n",
    "        print(f\"  Group {group} - Val Loss: {np.mean(group_val_loss_histories[group][-1]):.4f}, Val Accuracy: {np.mean(group_val_accuracy_histories[group][-1]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f5b0d-19b9-4050-b245-6d13078d0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class MultiStreamNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiStreamNet, self).__init__()\n",
    "\n",
    "        # Define the streams\n",
    "        self.stream_1 = resnet50(pretrained=True, progress=True, num_classes=64)  # First stream using resnet50\n",
    "        self.stream_2 = NN_beam_pred(num_features=4, num_output=64)  # Second stream using NN_beam_pred\n",
    "        \n",
    "        # Add Batch Normalization layers\n",
    "        self.bn_stream_1 = nn.BatchNorm1d(128)  # Adjust according to the output size of resnet50\n",
    "        self.bn_stream_2 = nn.BatchNorm1d(128)   # Adjust according to the output size of NN_beam_pred\n",
    "\n",
    "        # Combine the two streams and apply Multinomial Logistic Regression\n",
    "        self.fc = MultinomialLogisticRegression(input_size=256, num_classes=64)  # Adjust input_size & num_classes\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Process through stream 1 (resnet50)\n",
    "        out1 = self.stream_1(x1)\n",
    "        out2 = self.bn_stream_1(out1)\n",
    "        print(out1.shape)\n",
    "        print(out2.shape)\n",
    "        \n",
    "        # Process through stream 2 (NN_beam_pred)\n",
    "        out2 = self.stream_2(x2)\n",
    "        out2 = self.bn_stream_2(out2)\n",
    "\n",
    "        # Concatenate the outputs from both streams\n",
    "        out = torch.cat((out1, out2), dim=1)\n",
    "        \n",
    "        # Final classification layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "model = MultiStreamNet().to(device)\n",
    "\n",
    "# Set the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example training loop\n",
    "def train(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            x, y = data  # Assuming inputs1 and inputs2 are from different streams\n",
    "            x[\"images\"], x[\"pos_height\"], y = x[\"images\"].to(device), x[\"pos_height\"].to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(x[\"images\"], x[\"pos_height\"])\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Print average loss per epoch\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Assuming `train_loader` is a DataLoader object containing the training data\n",
    "train(model, train_loaders[0], criterion, optimizer)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6e4d18-b3ff-4a6f-b813-e1db3738d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = global_rounds\n",
    "# Convert metrics to numpy arrays for easy manipulation\n",
    "group_train_loss_histories = {k: np.array(v) for k, v in group_train_loss_histories.items()}\n",
    "group_train_accuracy_histories = {k: np.array(v) for k, v in group_train_accuracy_histories.items()}\n",
    "group_val_loss_histories = {k: np.array(v) for k, v in group_val_loss_histories.items()}\n",
    "group_val_accuracy_histories = {k: np.array(v) for k, v in group_val_accuracy_histories.items()}\n",
    "\n",
    "# Handle potential one-dimensional arrays\n",
    "group_train_loss_mean = {k: v.mean(axis=1) if v.ndim > 1 else v for k, v in group_train_loss_histories.items()}\n",
    "group_train_loss_std = {k: v.std(axis=1) if v.ndim > 1 else np.zeros_like(v) for k, v in group_train_loss_histories.items()}\n",
    "group_val_loss_mean = {k: v.mean(axis=1) if v.ndim > 1 else v for k, v in group_val_loss_histories.items()}\n",
    "group_val_loss_std = {k: v.std(axis=1) if v.ndim > 1 else np.zeros_like(v) for k, v in group_val_loss_histories.items()}\n",
    "\n",
    "group_train_acc_mean = {k: v.mean(axis=1) if v.ndim > 1 else v for k, v in group_train_accuracy_histories.items()}\n",
    "group_train_acc_std = {k: v.std(axis=1) if v.ndim > 1 else np.zeros_like(v) for k, v in group_train_accuracy_histories.items()}\n",
    "group_val_acc_mean = {k: v.mean(axis=1) if v.ndim > 1 else v for k, v in group_val_accuracy_histories.items()}\n",
    "group_val_acc_std = {k: v.std(axis=1) if v.ndim > 1 else np.zeros_like(v) for k, v in group_val_accuracy_histories.items()}\n",
    "\n",
    "# Combined Plot for All Modalities\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "for group in [1, 2, 3]:\n",
    "    plt.plot(range(1, num_epochs + 1), group_train_loss_mean[group], label=f\"Group {group} Train Loss\")\n",
    "    plt.fill_between(range(1, num_epochs + 1), \n",
    "                     group_train_loss_mean[group] - group_train_loss_std[group], \n",
    "                     group_train_loss_mean[group] + group_train_loss_std[group], \n",
    "                     alpha=0.2)\n",
    "    plt.plot(range(1, num_epochs + 1), group_val_loss_mean[group], label=f\"Group {group} Validation Loss\", linestyle=\"dashed\")\n",
    "    plt.fill_between(range(1, num_epochs + 1), \n",
    "                     group_val_loss_mean[group] - group_val_loss_std[group], \n",
    "                     group_val_loss_mean[group] + group_val_loss_std[group], \n",
    "                     alpha=0.2)\n",
    "\n",
    "plt.title(\"Loss over Epochs for All Groups\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "for group in [1, 2, 3]:\n",
    "    plt.plot(range(1, num_epochs + 1), group_train_acc_mean[group], label=f\"Group {group} Train Accuracy\")\n",
    "    plt.fill_between(range(1, num_epochs + 1), \n",
    "                     group_train_acc_mean[group] - group_train_acc_std[group], \n",
    "                     group_train_acc_mean[group] + group_train_acc_std[group], \n",
    "                     alpha=0.2)\n",
    "    plt.plot(range(1, num_epochs + 1), group_val_acc_mean[group], label=f\"Group {group} Validation Accuracy\", linestyle=\"dashed\")\n",
    "    plt.fill_between(range(1, num_epochs + 1), \n",
    "                     group_val_acc_mean[group] - group_val_acc_std[group], \n",
    "                     group_val_acc_mean[group] + group_val_acc_std[group], \n",
    "                     alpha=0.2)\n",
    "\n",
    "plt.title(\"Accuracy over Epochs for All Groups\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([0, 1])  # Ensure y-axis is between 0 and 1 for accuracy\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef6bc25-66fc-463b-bf3b-649b95dad7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert numpy arrays to lists for serialization\n",
    "data_to_save = {\n",
    "    \"group_train_loss_mean\": {k: v.tolist() for k, v in group_train_loss_mean.items()},\n",
    "    \"group_train_loss_std\": {k: v.tolist() for k, v in group_train_loss_std.items()},\n",
    "    \"group_val_loss_mean\": {k: v.tolist() for k, v in group_val_loss_mean.items()},\n",
    "    \"group_val_loss_std\": {k: v.tolist() for k, v in group_val_loss_std.items()},\n",
    "    \"group_train_acc_mean\": {k: v.tolist() for k, v in group_train_acc_mean.items()},\n",
    "    \"group_train_acc_std\": {k: v.tolist() for k, v in group_train_acc_std.items()},\n",
    "    \"group_val_acc_mean\": {k: v.tolist() for k, v in group_val_acc_mean.items()},\n",
    "    \"group_val_acc_std\": {k: v.tolist() for k, v in group_val_acc_std.items()}\n",
    "}\n",
    "\n",
    "with open(\"centralized_drone.json\", \"w\") as f:\n",
    "    json.dump(data_to_save, f)\n",
    "print(\"DSGD_metrics.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
