{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b537c0-5308-494e-b479-df1ed1fd34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transf\n",
    "from data_feed import DataFeed, DataFeed_image_pos\n",
    "from build_net import resnet50, NN_beam_pred, MultinomialLogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa17e9f-2958-489b-af3e-4dab1dfe1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# or full reproducibility\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38bfa9a-c6ef-450a-9180-61eb294a2ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Now you can use the `device` variable to move your model and data to the correct device\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be724f96-0c63-47c8-ad68-1b617c05d244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Overview:\n",
      "   index_x  unit2_lat  unit2_lon  unit2_height  unit2_distance  \\\n",
      "0     9862   0.188929   0.431909      1.000000        0.167641   \n",
      "1     4449   0.410610   0.286188      0.231752        0.361212   \n",
      "2    10299   0.365071   0.424029      0.174270        0.246799   \n",
      "3     9229   0.335884   0.431909      0.656934        0.210932   \n",
      "4     6947   0.175857   0.390571      0.056569        0.242568   \n",
      "\n",
      "                                           unit1_rgb  unit1_beam_x  \\\n",
      "0  ./../Carla/datasets/scenario23_dev//unit1/came...            17   \n",
      "1  ./../Carla/datasets/scenario23_dev//unit1/came...            14   \n",
      "2  ./../Carla/datasets/scenario23_dev//unit1/came...            20   \n",
      "3  ./../Carla/datasets/scenario23_dev//unit1/came...            17   \n",
      "4  ./../Carla/datasets/scenario23_dev//unit1/came...            14   \n",
      "\n",
      "   lat_region  lon_region  region  \n",
      "0           0           1       1  \n",
      "1           1           0       2  \n",
      "2           1           1       3  \n",
      "3           1           1       3  \n",
      "4           0           0       0  \n",
      "\n",
      "Data Summary:\n",
      "            index_x   unit2_lat   unit2_lon  unit2_height  unit2_distance  \\\n",
      "count    570.000000  570.000000  570.000000    570.000000      570.000000   \n",
      "mean    5765.140351    0.339799    0.404146      0.326157        0.276529   \n",
      "std     3235.268614    0.154570    0.105268      0.267289        0.152336   \n",
      "min       20.000000    0.030779    0.081985      0.017336        0.001901   \n",
      "25%     3018.500000    0.226024    0.352309      0.092153        0.173065   \n",
      "50%     5894.500000    0.306971    0.412554      0.208029        0.231712   \n",
      "75%     8530.500000    0.399213    0.451542      0.552007        0.357941   \n",
      "max    11349.000000    0.981461    0.845154      1.000000        0.920808   \n",
      "\n",
      "       unit1_beam_x  lat_region  lon_region      region  \n",
      "count    570.000000  570.000000  570.000000  570.000000  \n",
      "mean      15.608772    0.492982    0.524561    1.510526  \n",
      "std        4.621672    0.500390    0.499835    1.181608  \n",
      "min        2.000000    0.000000    0.000000    0.000000  \n",
      "25%       14.000000    0.000000    0.000000    0.000000  \n",
      "50%       16.000000    0.000000    1.000000    1.000000  \n",
      "75%       17.000000    1.000000    1.000000    3.000000  \n",
      "max       30.000000    1.000000    1.000000    3.000000  \n",
      "\n",
      "Missing Values:\n",
      "index_x           0\n",
      "unit2_lat         0\n",
      "unit2_lon         0\n",
      "unit2_height      0\n",
      "unit2_distance    0\n",
      "unit1_rgb         0\n",
      "unit1_beam_x      0\n",
      "lat_region        0\n",
      "lon_region        0\n",
      "region            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the saved CSV files\n",
    "output_dir = \"./feature_IID/\"\n",
    "\n",
    "# Load one of the CSV files for EDA (e.g., user_0_outputs.csv)\n",
    "df = pd.read_csv(output_dir + \"user_0_pos_height_beam.csv\")\n",
    "\n",
    "# Quick overview of the data\n",
    "print(\"Data Overview:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43bf9b52-16e1-4ec8-acd5-1cbd19cab71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All loadred are loaded\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "########################### Data pre-processing ########################\n",
    "########################################################################\n",
    "no_users = 20\n",
    "batch_size = 64\n",
    "img_resize = transf.Resize((224, 224))\n",
    "img_norm = transf.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "proc_pipe = transf.Compose(\n",
    "    [transf.ToPILImage(),\n",
    "     img_resize,\n",
    "     transf.ToTensor(),\n",
    "     img_norm]\n",
    ")\n",
    "dataset_dir = \"feature_IID/\"\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "val_loaders = []\n",
    "\n",
    "for user_id in range(no_users):\n",
    "    train_dir = dataset_dir + f'user_{user_id}_pos_height_beam_train.csv'\n",
    "    val_dir = dataset_dir + f'user_{user_id}_pos_height_beam_val.csv'\n",
    "    test_dir = dataset_dir + f'user_{user_id}_pos_height_beam_test.csv'\n",
    "    \n",
    "    train_dataset = DataFeed_image_pos(train_dir, transform=proc_pipe)\n",
    "    val_dataset = DataFeed_image_pos(root_dir=val_dir, transform=proc_pipe)\n",
    "    test_dataset = DataFeed_image_pos(root_dir=test_dir, transform=proc_pipe)\n",
    "    \n",
    "    \n",
    "    train_loaders.append(DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              #num_workers=8,\n",
    "                              shuffle=False))\n",
    "    val_loaders.append(DataLoader(val_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            #num_workers=8,\n",
    "                            shuffle=False))\n",
    "    test_loaders.append(DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            #num_workers=8,\n",
    "                            shuffle=False))\n",
    "print(\"All loadred are loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2aeb40-49ab-4536-a119-acf212a41a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Preperation#\n",
    "all_models = []\n",
    "available_modalities = [\"pos_height\", \"images\"]\n",
    "user_modalities = [available_modalities for _ in range(no_users)]\n",
    "modality_size = {\"pos_height\": 128, \"images\": 128}\n",
    "output_sizes = [sum([modality_size[i] for i in user_modality]) for user_modality in user_modalities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5627ec-2bc5-406a-bed8-a058e4a728b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Groups: [3, 1, 2, 2, 3, 3, 3, 1, 2, 1]\n",
      "User Modalities: [['pos_height', 'images'], ['pos_height'], ['images'], ['images'], ['pos_height', 'images'], ['pos_height', 'images'], ['pos_height', 'images'], ['pos_height'], ['images'], ['pos_height']]\n",
      "Output Sizes: [256, 128, 128, 128, 256, 256, 256, 128, 128, 128]\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "no_users = 20  # Example: Number of users\n",
    "available_modalities = [\"pos_height\", \"images\"]\n",
    "modality_size = {\"pos_height\": 128, \"images\": 128}\n",
    "group_definitions = {\n",
    "    1: [\"pos_height\"],        # Group 1: Only pos_height\n",
    "    2: [\"images\"],            # Group 2: Only images\n",
    "    3: [\"pos_height\", \"images\"]  # Group 3: Both modalities\n",
    "}\n",
    "\n",
    "# Assign each user to a group randomly\n",
    "weights = [0.2, 0.3, 0.5]  # Probabilities for groups 1, 2, and 3\n",
    "\n",
    "# Generate user_groups with weighted random choices\n",
    "user_groups = random.choices([1, 2, 3], weights=weights, k=no_users)\n",
    "\n",
    "# Assign modalities to users based on their group\n",
    "user_modalities = [group_definitions[group] for group in user_groups]\n",
    "\n",
    "# Compute output sizes for each user based on their modalities\n",
    "output_sizes = [sum(modality_size[modality] for modality in user_modality) for user_modality in user_modalities]\n",
    "\n",
    "# Store models (placeholders for actual models)\n",
    "all_models = []\n",
    "\n",
    "# Example output (for verification)\n",
    "print(f\"User Groups: {user_groups[:10]}\")  # Show first 10 users' groups\n",
    "print(f\"User Modalities: {user_modalities[:10]}\")  # Show first 10 users' modalities\n",
    "print(f\"Output Sizes: {output_sizes[:10]}\")  # Show first 10 users' output sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed4d5c-f244-40b5-9036-25a31edc6e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388f5b0d-19b9-4050-b245-6d13078d0066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer dim = 64\n",
      "<class 'build_net.Bottleneck'>\n",
      "torch.Size([64, 128])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'out2' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Assuming `train_loader` is a DataLoader object containing the training data\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[0;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpos_height\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m     56\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sionna_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sionna_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m, in \u001b[0;36mMultiStreamNet.forward\u001b[1;34m(self, x1, x2)\u001b[0m\n\u001b[0;32m     19\u001b[0m out1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_stream_1(out1)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(out1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mout2\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Process through stream 2 (NN_beam_pred)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m out2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_2(x2)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'out2' referenced before assignment"
     ]
    }
   ],
   "source": [
    "class MultiStreamNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiStreamNet, self).__init__()\n",
    "\n",
    "        # Define the streams\n",
    "        self.stream_1 = resnet50(pretrained=True, progress=True, num_classes=64)  # First stream using resnet50\n",
    "        self.stream_2 = NN_beam_pred(num_features=4, num_output=64)  # Second stream using NN_beam_pred\n",
    "        \n",
    "        # Add Batch Normalization layers\n",
    "        self.bn_stream_1 = nn.BatchNorm1d(128)  # Adjust according to the output size of resnet50\n",
    "        self.bn_stream_2 = nn.BatchNorm1d(128)   # Adjust according to the output size of NN_beam_pred\n",
    "\n",
    "        # Combine the two streams and apply Multinomial Logistic Regression\n",
    "        self.fc = MultinomialLogisticRegression(input_size=2304, num_classes=10)  # Adjust input_size & num_classes\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Process through stream 1 (resnet50)\n",
    "        out1 = self.stream_1(x1)\n",
    "        out2 = self.bn_stream_1(out1)\n",
    "        print(out1.shape)\n",
    "        print(out2.shape)\n",
    "        \n",
    "        # Process through stream 2 (NN_beam_pred)\n",
    "        out2 = self.stream_2(x2)\n",
    "        out2 = self.bn_stream_2(out2)\n",
    "\n",
    "        # Concatenate the outputs from both streams\n",
    "        out = torch.cat((out1, out2), dim=1)\n",
    "        \n",
    "        # Final classification layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "model = MultiStreamNet().to(device)\n",
    "\n",
    "# Set the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example training loop\n",
    "def train(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            x, y = data  # Assuming inputs1 and inputs2 are from different streams\n",
    "            x[\"images\"], x[\"pos_height\"], y = x[\"images\"].to(device), x[\"pos_height\"].to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(x[\"images\"], x[\"pos_height\"])\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Print average loss per epoch\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Assuming `train_loader` is a DataLoader object containing the training data\n",
    "train(model, train_loaders[0], criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6e4d18-b3ff-4a6f-b813-e1db3738d044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
