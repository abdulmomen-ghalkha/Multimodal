{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b537c0-5308-494e-b479-df1ed1fd34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transf\n",
    "from data_feed import DataFeed, DataFeed_image_pos\n",
    "from build_net import resnet50, NN_beam_pred, MultinomialLogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa17e9f-2958-489b-af3e-4dab1dfe1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# or full reproducibility\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38bfa9a-c6ef-450a-9180-61eb294a2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Now you can use the `device` variable to move your model and data to the correct device\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be724f96-0c63-47c8-ad68-1b617c05d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the saved CSV files\n",
    "output_dir = \"./feature_IID/\"\n",
    "\n",
    "# Load one of the CSV files for EDA (e.g., user_0_outputs.csv)\n",
    "df = pd.read_csv(output_dir + \"user_0_pos_height_beam.csv\")\n",
    "\n",
    "# Quick overview of the data\n",
    "print(\"Data Overview:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf9b52-16e1-4ec8-acd5-1cbd19cab71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "########################### Data pre-processing ########################\n",
    "########################################################################\n",
    "no_users = 20\n",
    "batch_size = 64\n",
    "img_resize = transf.Resize((224, 224))\n",
    "img_norm = transf.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "proc_pipe = transf.Compose(\n",
    "    [transf.ToPILImage(),\n",
    "     img_resize,\n",
    "     transf.ToTensor(),\n",
    "     img_norm]\n",
    ")\n",
    "dataset_dir = \"feature_IID/\"\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "val_loaders = []\n",
    "\n",
    "for user_id in range(no_users):\n",
    "    train_dir = dataset_dir + f'user_{user_id}_pos_height_beam_train.csv'\n",
    "    val_dir = dataset_dir + f'user_{user_id}_pos_height_beam_val.csv'\n",
    "    test_dir = dataset_dir + f'user_{user_id}_pos_height_beam_test.csv'\n",
    "    \n",
    "    train_dataset = DataFeed_image_pos(train_dir, transform=proc_pipe)\n",
    "    val_dataset = DataFeed_image_pos(root_dir=val_dir, transform=proc_pipe)\n",
    "    test_dataset = DataFeed_image_pos(root_dir=test_dir, transform=proc_pipe)\n",
    "    \n",
    "    \n",
    "    train_loaders.append(DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              #num_workers=8,\n",
    "                              shuffle=False))\n",
    "    val_loaders.append(DataLoader(val_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            #num_workers=8,\n",
    "                            shuffle=False))\n",
    "    test_loaders.append(DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            #num_workers=8,\n",
    "                            shuffle=False))\n",
    "print(\"All loadred are loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2aeb40-49ab-4536-a119-acf212a41a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Preperation#\n",
    "all_models = []\n",
    "available_modalities = [\"pos_height\", \"images\"]\n",
    "modality_size = {\"pos_height\": 128, \"images\": 128}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5627ec-2bc5-406a-bed8-a058e4a728b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "import random\n",
    "no_users = 20  # Example: Number of users\n",
    "available_modalities = [\"pos_height\", \"images\"]\n",
    "modality_size = {\"pos_height\": 128, \"images\": 128}\n",
    "group_definitions = {\n",
    "    1: [\"pos_height\"],        # Group 1: Only pos_height\n",
    "    2: [\"images\"],            # Group 2: Only images\n",
    "    3: [\"pos_height\", \"images\"]  # Group 3: Both modalities\n",
    "}\n",
    "\n",
    "# Assign each user to a group randomly\n",
    "weights = [0.2, 0.3, 0.5]  # Probabilities for groups 1, 2, and 3\n",
    "\n",
    "# Generate user_groups with weighted random choices\n",
    "user_groups = random.choices([1, 2, 3], weights=weights, k=no_users)\n",
    "\n",
    "# Assign modalities to users based on their group\n",
    "user_modalities = [group_definitions[group] for group in user_groups]\n",
    "\n",
    "# Compute output sizes for each user based on their modalities\n",
    "output_sizes = [sum(modality_size[modality] for modality in user_modality) for user_modality in user_modalities]\n",
    "\n",
    "# Store models (placeholders for actual models)\n",
    "all_models = []\n",
    "\n",
    "# Example output (for verification)\n",
    "print(f\"User Groups: {user_groups[:10]}\")  # Show first 10 users' groups\n",
    "print(f\"User Modalities: {user_modalities[:10]}\")  # Show first 10 users' modalities\n",
    "print(f\"Output Sizes: {output_sizes[:10]}\")  # Show first 10 users' output sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed4d5c-f244-40b5-9036-25a31edc6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_knopp(matrix, tol=1e-9, max_iter=1000):\n",
    "    \"\"\"\n",
    "    Converts a given matrix to a doubly stochastic matrix using the Sinkhorn-Knopp algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "        matrix (np.ndarray): The input matrix to be transformed.\n",
    "        tol (float): The tolerance for convergence.\n",
    "        max_iter (int): Maximum number of iterations for convergence.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A doubly stochastic matrix.\n",
    "    \"\"\"\n",
    "    matrix = matrix.copy()\n",
    "    for _ in range(max_iter):\n",
    "        # Normalize rows\n",
    "        row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "        matrix /= row_sums\n",
    "\n",
    "        # Normalize columns\n",
    "        col_sums = matrix.sum(axis=0, keepdims=True)\n",
    "        matrix /= col_sums\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.allclose(matrix.sum(axis=1), 1, atol=tol) and np.allclose(matrix.sum(axis=0), 1, atol=tol):\n",
    "            break\n",
    "\n",
    "    return matrix\n",
    "    \n",
    "def create_random_topology(num_users, similarity_matrix, edge_probability=0.3):\n",
    "    \"\"\"\n",
    "    Creates a connected random topology using NetworkX.\n",
    "    Returns the adjacency matrix.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        graph = nx.erdos_renyi_graph(num_users, edge_probability)\n",
    "        adjacency_matrix = nx.to_numpy_array(graph)\n",
    "        new_adj = np.multiply(adjacency_matrix, similarity_matrix)\n",
    "        new_graph = nx.from_numpy_array(new_adj)\n",
    "        if nx.is_connected(new_graph):\n",
    "            break\n",
    "\n",
    "    # Convert graph to adjacency matrix\n",
    "    adjacency_matrix = nx.to_numpy_array(new_graph)\n",
    "    return adjacency_matrix\n",
    "\n",
    "def prepare_mixing_matrices(adjacency_matrix, similarity_matrices):\n",
    "    \"\"\"\n",
    "    Computes a mixing matrix for each modality by multiplying the adjacency matrix \n",
    "    with the similarity matrix for that modality.\n",
    "    Returns a dictionary of mixing matrices.\n",
    "    \"\"\"\n",
    "    adjacency_matrices = {}\n",
    "    mixing_matrices = {}\n",
    "    for modality, similarity_matrix in similarity_matrices.items():\n",
    "        # Element-wise multiplication of adjacency and similarity matrices\n",
    "        combined_matrix = adjacency_matrix * similarity_matrix\n",
    "        adjacency_matrices[modality] = combined_matrix\n",
    "        \n",
    "        # Normalize to create a doubly matrix\n",
    "        mixing_matrix = sinkhorn_knopp(combined_matrix)\n",
    "        \n",
    "        \n",
    "        mixing_matrices[modality] = mixing_matrix\n",
    "    \n",
    "    return mixing_matrices, adjacency_matrices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df528594-e32b-4cf3-8dd4-af4e5a428428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random connected topology\n",
    "#adjacency_matrix = create_random_topology(no_users, edge_probability=0.3)\n",
    "# Initialize adjacency matrix\n",
    "similarity_matrix = np.zeros((no_users, no_users), dtype=int)\n",
    "\n",
    "# Construct the adjacency matrix\n",
    "for i in range(no_users):\n",
    "    for j in range(no_users):\n",
    "        if i != j:  # No self-loops\n",
    "            # Check if users i and j share any modalities\n",
    "            if set(user_modalities[i]) & set(user_modalities[j]):\n",
    "                similarity_matrix[i, j] = 1\n",
    "\n",
    "# Display the adjacency matrix\n",
    "print(\"Adjacency Matrix:\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "# Prepare mixing matrices for each modality\n",
    "#mixing_matrices, adjacency_matrices = prepare_mixing_matrices(adjacency_matrix, similarity_matrices)\n",
    "adjacency_matrix = create_random_topology(20, similarity_matrix, edge_probability=0.3)\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c612d-004b-499c-b98a-a5d0cef8cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph\n",
    "# Define colors for the groups\n",
    "group_colors = {1: 'red', 2: 'green', 3: 'blue'}\n",
    "node_colors = [group_colors[group] for group in user_groups]\n",
    "G = nx.from_numpy_array(similarity_matrix)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, edge_color='gray', node_size=1000, node_color=node_colors, font_size=20, font_color='black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a429b-e190-44c7-b192-4546fac4aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph\n",
    "G = nx.from_numpy_array(adjacency_matrix)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, edge_color='gray', node_size=1000, node_color=node_colors, font_size=20, font_color='black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "print(user_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d13f9-412a-4aff-a6f9-b5874d4e720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity matrices\n",
    "adj_per_modality = {}\n",
    "for modality in available_modalities:\n",
    "    adj = np.zeros((no_users, no_users))\n",
    "    for node in range(no_users):\n",
    "        for neighbor in G.neighbors(node):\n",
    "            if modality in user_modalities[neighbor] and modality in user_modalities[node]:\n",
    "                adj[node, neighbor] = 1.    \n",
    "    adj_per_modality[modality] = adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777c2e2-57fe-4b72-9203-b2ff52032787",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_modality = nx.from_numpy_array(adj_per_modality[\"images\"])\n",
    "pos = nx.spring_layout(G_modality)\n",
    "nx.draw(G_modality, pos, with_labels=True, edge_color='gray', node_size=1000, node_color=node_colors, font_size=20, font_color='black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d52df-5b53-4854-b693-aa3c55bc3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_mixing_matrix(Adj, method=\"metropolis\"):\n",
    "    n = Adj.shape[0]\n",
    "    W = np.zeros((n, n))  # Initialize weight matrix\n",
    "\n",
    "    for i in range(n):\n",
    "        degree_i = np.sum(Adj[i, :])\n",
    "\n",
    "        for j in range(n):\n",
    "            if Adj[i, j] == 1.0:\n",
    "                degree_j = np.sum(Adj[j, :])\n",
    "    \n",
    "                if method == \"metropolis\":\n",
    "                    W[i, j] = 1 / (max(degree_i, degree_j) + 1)\n",
    "                elif method == \"uniform\":\n",
    "                    W[i, j] = 1 / degree_i\n",
    "\n",
    "        # Diagonal weight\n",
    "        W[i, i] = 1 - np.sum(W[i, :])\n",
    "\n",
    "    return W\n",
    "\n",
    "mixing_matrices = {}\n",
    "for modality in available_modalities:\n",
    "    mixing_matrices[modality] = construct_mixing_matrix(adj_per_modality[modality], method=\"metropolis\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f06211-192b-4932-a918-b9fe5407bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_modality = nx.from_numpy_array(adj_per_modality[\"pos_height\"])\n",
    "pos = nx.spring_layout(G_modality)\n",
    "largest_cc = max(nx.connected_components(G_modality), key=len)\n",
    "\n",
    "# Convert to sorted list of indices\n",
    "connected_nodes = sorted(largest_cc)\n",
    "\n",
    "# Extract the submatrix corresponding to the connected subgraph\n",
    "W_reduced = mixing_matrices[\"pos_height\"][np.ix_(connected_nodes, connected_nodes)]\n",
    "lamb = np.linalg.eigvals(W_reduced)\n",
    "lamb.sort()\n",
    "print(lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64903e-aade-4ec3-b367-87a0a339a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Feature Extractor\n",
    "class ImageFeatureExtractor(nn.Module):\n",
    "    def __init__(self, output_dim=128):\n",
    "        super(ImageFeatureExtractor, self).__init__()\n",
    "        base_model = resnet50(pretrained=True, num_classes=64)\n",
    "        #base_model.fc = nn.Identity()  # Remove classification layer\n",
    "        self.feature_extractor = base_model\n",
    "        #self.fc = nn.Linear(128, output_dim)  # Project to desired output dimension\n",
    "        self.bn = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        #x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "# Position Feature Extractor\n",
    "class PosFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim=4, output_dim=128):\n",
    "        super(PosFeatureExtractor, self).__init__()\n",
    "        self.feature_extractor = NN_beam_pred(num_features=input_dim, num_output=output_dim)\n",
    "        self.bn = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "# Classification Head\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=64):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Main Model with Named Sub-Networks\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, use_image=True, use_pos=True, feature_dim=128, num_classes=64):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        # Store sub-networks in a dictionary\n",
    "        self.sub_networks = nn.ModuleDict()\n",
    "\n",
    "        if use_image:\n",
    "            self.sub_networks[\"images\"] = ImageFeatureExtractor(output_dim=feature_dim)\n",
    "        if use_pos:\n",
    "            self.sub_networks[\"pos_height\"] = PosFeatureExtractor(output_dim=feature_dim)\n",
    "\n",
    "        # Determine input size for classification head\n",
    "        input_dim = (feature_dim if use_image else 0) + (feature_dim if use_pos else 0)\n",
    "        self.classifier = ClassificationHead(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, images=None, pos_height=None):\n",
    "        features = []\n",
    "\n",
    "        if \"images\" in self.sub_networks and images is not None:\n",
    "            features.append(self.sub_networks[\"images\"](images))\n",
    "\n",
    "        if \"pos_height\" in self.sub_networks and pos_height is not None:\n",
    "            features.append(self.sub_networks[\"pos_height\"](pos_height))\n",
    "\n",
    "        if not features:\n",
    "            raise ValueError(\"At least one modality (image or pos) must be used\")\n",
    "\n",
    "        x = torch.cat(features, dim=1) if len(features) > 1 else features[0]\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309ef97-61c6-474b-a9f6-6f2643ce39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(use_image=True, use_pos=True)\n",
    "\n",
    "# Extract the image feature extractor using its name\n",
    "image_extractor = model.sub_networks[\"pos_height\"]\n",
    "\n",
    "classifier_head = model.classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae3a6e-a849-437b-9a1b-805749fd0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = optim.Adam(model.sub_networks[\"pos_height\"].parameters(), lr=1e-3)\n",
    "optimizer2 = optim.Adam(model.sub_networks[\"images\"].parameters(), lr=1e-3)\n",
    "optimizer3 = optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8e084-7f9b-4154-ae3d-fe001158cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training function with accuracy calculation\n",
    "def train(model, train_loader, criterion, optimizer, epochs=10, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for data in train_loader:\n",
    "            x, y = data  # Assuming inputs1 and inputs2 are from different streams\n",
    "            x[\"images\"], x[\"pos_height\"], y = x[\"images\"].to(device), x[\"pos_height\"].to(device), y.to(device)\n",
    "\n",
    "            optimizer1.zero_grad()\n",
    "            optimizer2.zero_grad()\n",
    "            optimizer3.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(image=x[\"images\"], pos=x[\"pos_height\"])\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer1.step()\n",
    "            optimizer2.step()\n",
    "            optimizer3.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Compute Accuracy\n",
    "            _, predicted = torch.max(outputs, 1)  # Get class index with highest probability\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        # Calculate accuracy for the epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct / total * 100  # Convert to percentage\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "# Assuming `train_loader` is a DataLoader object containing the training data\n",
    "#train(model, train_loaders[0], criterion, optimizer, epochs=10, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca511b8-585b-4698-a6bc-bfb3ab69ea83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optimizers = []\n",
    "all_models = []\n",
    "classifier_optimizers = []\n",
    "for user_id in range(no_users):\n",
    "    if \"images\" in user_modalities[user_id] and \"pos_height\" in user_modalities[user_id]:\n",
    "        user_model = Classifier(use_image=True, use_pos=True).to(device)\n",
    "    elif \"pos_height\" in user_modalities[user_id]:\n",
    "        user_model = Classifier(use_image=False, use_pos=True).to(device)\n",
    "    elif \"images\" in user_modalities[user_id]:\n",
    "        user_model = Classifier(use_image=True, use_pos=False).to(device)\n",
    "    local_optimizer = optim.Adam(user_model.parameters(), lr=lr)\n",
    "    class_optim = optim.Adam(user_model.classifier.parameters(), lr=lr)\n",
    "\n",
    "    all_models.append(user_model)\n",
    "    optimizers.append(local_optimizer)\n",
    "    classifier_optimizers.append(class_optim)\n",
    "base_models = Classifier(use_image=True, use_pos=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d76d7c-3c9c-4037-ab8d-bb833720af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 0.001\n",
    "neighbors = [np.nonzero(adjacency_matrix[i])[0].tolist() for i in range(no_users)]\n",
    "\n",
    "# Initialize P_ij matrices\n",
    "# Initialize P_ij matrices\n",
    "P = {}\n",
    "for i, j in zip(*adjacency_matrix.nonzero()):\n",
    "    num_params_i = sum(p.numel() for p in all_models[i].classifier.parameters())\n",
    "    num_params_j = sum(p.numel() for p in all_models[j].classifier.parameters())\n",
    "    P[(i, j)] = torch.eye(int(factor*(num_params_i + num_params_j) // 2), num_params_i).to(device)\n",
    "    P[(j, i)] = torch.eye(int(factor*(num_params_i + num_params_j) // 2), num_params_j).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ccd1e-5893-492e-aaf8-7406a37793fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Decentralized aggregation function\n",
    "def per_modelaity_decentralized_aggregation(user_models, mixing_matrices, available_modalities, user_modalities, base_models):\n",
    "    num_users = len(user_models)\n",
    "    for modality in available_modalities:\n",
    "        # Get the mixing matrix for the current modality\n",
    "        mixing_matrix = mixing_matrices[modality]\n",
    "        \n",
    "        # Convert user model parameters to vectors for aggregation\n",
    "        aggregated_models = []\n",
    "        aggregated_updates = []\n",
    "        for user_id, user_model in enumerate(user_models):\n",
    "            if modality in user_modalities[user_id]:\n",
    "                aggregated_models.append(torch.nn.utils.parameters_to_vector(user_model.sub_networks[modality].parameters()))\n",
    "                aggregated_updates.append(torch.zeros_like(aggregated_models[-1]))\n",
    "            else:\n",
    "                aggregated_models.append(0)\n",
    "                aggregated_updates.append(0)\n",
    "        \n",
    "        \n",
    "        # Perform model aggregation based on the mixing matrix for this modality\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_users):\n",
    "                if mixing_matrix[i, j] > 0:\n",
    "                    aggregated_updates[i] += mixing_matrix[i, j] * aggregated_models[j]\n",
    "        \n",
    "        # Update user models with aggregated parameters for the current modality\n",
    "        for user_id in range(num_users):\n",
    "            if modality in user_modalities[user_id]:\n",
    "                torch.nn.utils.vector_to_parameters(aggregated_updates[user_id], user_models[user_id].sub_networks[modality].parameters())\n",
    "\n",
    "#per_modelaity_decentralized_aggregation(all_models, mixing_matrices, available_modalities, user_modalities, base_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a9edf-0c2f-4130-97ba-bf5629d53db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_local_model(local_modalities, model, train_loader, criterion, optimizer, epochs, device):\n",
    "    \"\"\"\n",
    "    Trains a local multi-modal model.\n",
    "\n",
    "    Args:\n",
    "        local_modalities (list): Modalities to use (e.g., ['image', 'pos']).\n",
    "        model (Classifier): Multi-modal classification model.\n",
    "        train_loader (DataLoader): Training data loader.\n",
    "        criterion (nn.CrossEntropyLoss): Loss function.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer.\n",
    "        epochs (int): Number of training epochs.\n",
    "        device (torch.device): Device (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Minimum training loss, maximum training accuracy.\n",
    "    \"\"\"\n",
    "    # Unfreeze the layers\n",
    "    # freezing first layers \n",
    "    for mod in local_modalities:\n",
    "        for param in model.sub_networks[mod].parameters():\n",
    "            param.requires_grad = True  # Freezes the feature extractor\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch\n",
    "\n",
    "            # Prepare input data for selected modalities\n",
    "            modality_inputs = {mod: inputs[mod].to(device) for mod in local_modalities}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(**modality_inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        # Compute loss and accuracy\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0\n",
    "\n",
    "        training_losses.append(avg_loss)\n",
    "        training_accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return min(training_losses), max(training_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1283f587-3182-4141-9c59-7123ee545153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_user_models(user_id, model, val_loader, criterion, local_modalities, device):\n",
    "    \"\"\"\n",
    "    Validates a trained multi-modal model.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): User identifier.\n",
    "        model (Classifier): Multi-modal classification model.\n",
    "        val_loader (DataLoader): Validation data loader.\n",
    "        criterion (nn.CrossEntropyLoss): Loss function.\n",
    "        local_modalities (list): Modalities to use (e.g., ['image', 'pos']).\n",
    "        device (torch.device): Device (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        dict: Validation loss and accuracy.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, labels = batch\n",
    "\n",
    "            # Prepare input data for selected modalities\n",
    "            modality_inputs = {mod: inputs[mod].to(device) for mod in local_modalities}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(**modality_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Compute loss and accuracy\n",
    "    avg_loss = total_loss / total_samples if total_samples > 0 else 0.0\n",
    "    accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "\n",
    "    print(f\"User {user_id + 1} - Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return {\"loss\": avg_loss, \"accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15760f17-e346-4fb2-994a-6669a60a97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def fmtl_aggregation(classifiers, optimizers, train_loaders, user_modalities, user_groups, no_users, adjacency_matrix, P, alpha, lambda_reg, eta, criterion, device):\n",
    "    \"\"\"\n",
    "    Perform FMTL Aggregation while only updating model.classifier.\n",
    "    \n",
    "    Args:\n",
    "        classifiers (dict): Dictionary of user classifier models.\n",
    "        optimizers (dict): Dictionary of user optimizers.\n",
    "        train_loaders (dict): Dictionary of user train loaders.\n",
    "        user_modalities (dict): Dictionary mapping each user to their available modalities.\n",
    "        user_groups (dict): Mapping of users to groups.\n",
    "        no_users (int): Number of users.\n",
    "        adjacency_matrix (torch.Tensor): Adjacency matrix for FMTL.\n",
    "        P (dict): Projection matrices for FMTL.\n",
    "        alpha (float): Learning rate scaling factor.\n",
    "        lambda_reg (float): Regularization parameter.\n",
    "        eta (float): Step size for projection updates.\n",
    "        criterion (torch.nn.Module): Loss function.\n",
    "        device (torch.device): Computation device.\n",
    "    \"\"\"\n",
    "\n",
    "    for user_id in range(no_users):\n",
    "        print(f\"FMTL: {user_id}\")\n",
    "        client_model = classifiers[user_id]  # Get user's model\n",
    "        optimizer = optimizers[user_id]      # Get optimizer\n",
    "        train_loader = train_loaders[user_id]  # Get train loader\n",
    "        modalities = user_modalities[user_id]  # Get list of modalities for user\n",
    "        group = user_groups[user_id]           # Get user's group\n",
    "\n",
    "        # freezing first layers \n",
    "        for mod in modalities:\n",
    "            for param in client_model.sub_networks[mod].parameters():\n",
    "                param.requires_grad = False  # Freezes the feature extractor\n",
    "\n",
    "        epoch_train_loss = 0.0\n",
    "        correct_train_predictions = 0\n",
    "        total_train_samples = 0\n",
    "\n",
    "        # Set model to training mode\n",
    "        client_model.train()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch\n",
    "\n",
    "            # Prepare input data for selected modalities\n",
    "            modality_inputs = {mod: inputs[mod].to(device) for mod in modalities}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass using selected modalities\n",
    "            predictions = client_model(**modality_inputs)\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            # Backpropagation (only for classifier)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += loss.item()\n",
    "            _, predicted = torch.max(predictions, dim=1)\n",
    "            correct_train_predictions += (predicted == labels).sum().item()\n",
    "            total_train_samples += labels.size(0)\n",
    "\n",
    "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_predictions / total_train_samples\n",
    "\n",
    "        # ==============================\n",
    "        #        FMTL Parameter Update\n",
    "        # ==============================\n",
    "        with torch.no_grad():\n",
    "            # Extract classifier parameters only\n",
    "            theta_i = torch.cat([param.view(-1) for param in client_model.classifier.parameters()])\n",
    "            sum_P_terms = torch.zeros_like(theta_i, device=device)\n",
    "            projection_norm = 0\n",
    "\n",
    "            for j in range(no_users):\n",
    "                if adjacency_matrix[user_id, j] == 1:\n",
    "                    P_ij = P[(user_id, j)]\n",
    "                    P_ji = P[(j, user_id)]\n",
    "                    theta_j = torch.cat([param.view(-1) for param in classifiers[j].classifier.parameters()])\n",
    "                    \n",
    "                    sum_P_terms += P_ij.T @ (P_ij @ theta_i - P_ji @ theta_j)\n",
    "                    projection_norm += torch.linalg.norm(P_ij @ theta_i - P_ji @ theta_j, ord=1, dim=0)\n",
    "\n",
    "            if user_id == 0:\n",
    "                print(f\"Norm of difference: {projection_norm}\")\n",
    "\n",
    "            # Apply FMTL update rule\n",
    "            theta_i -= alpha * lambda_reg * sum_P_terms\n",
    "\n",
    "            # Update classifier parameters only\n",
    "            idx = 0\n",
    "            for param in client_model.classifier.parameters():\n",
    "                numel = param.numel()\n",
    "                param.data.copy_(theta_i[idx:idx+numel].reshape(param.size()))\n",
    "                idx += numel\n",
    "\n",
    "            # Projection matrix update\n",
    "            for j in range(no_users):\n",
    "                if adjacency_matrix[user_id, j] == 1:\n",
    "                    P_ij = P[(user_id, j)]\n",
    "                    P_ji = P[(j, user_id)]\n",
    "                    theta_j = torch.cat([param.view(-1) for param in classifiers[j].classifier.parameters()])\n",
    "                    \n",
    "                    P[(user_id, j)] -= eta * lambda_reg * torch.outer(P_ij @ theta_i - P_ji @ theta_j, theta_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc54c0-b9d7-4533-a16e-a063d5b9b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Hyperparameters\n",
    "lambda_reg = 0.01\n",
    "eta = 0.01\n",
    "alpha = 1e-3\n",
    "# Dictionaries to store metrics\n",
    "group_train_loss_histories = {1: [], 2: [], 3: []}\n",
    "group_train_accuracy_histories = {1: [], 2: [], 3: []}\n",
    "group_val_loss_histories = {1: [], 2: [], 3: []}\n",
    "group_val_accuracy_histories = {1: [], 2: [], 3: []}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "global_rounds = 100\n",
    "local_epochs = 1\n",
    "\n",
    "# Decentralized Federated Learning Loop\n",
    "for round_num in range(global_rounds):\n",
    "    print(f\"Global Round {round_num + 1}\")\n",
    "\n",
    "    # Decentralized aggregation step\n",
    "\n",
    "    # Temporary storage for this round\n",
    "    epoch_group_train_losses = {1: [], 2: [], 3: []}\n",
    "    epoch_group_train_accuracies = {1: [], 2: [], 3: []}\n",
    "    epoch_group_val_losses = {1: [], 2: [], 3: []}\n",
    "    epoch_group_val_accuracies = {1: [], 2: [], 3: []}\n",
    "\n",
    "    per_modelaity_decentralized_aggregation(all_models, mixing_matrices, available_modalities, user_modalities, base_models)\n",
    "\n",
    "    fmtl_aggregation(all_models, classifier_optimizers, train_loaders, user_modalities, user_groups, no_users, adjacency_matrix, P, alpha, lambda_reg, eta, criterion, device)\n",
    "    print(\"FinishedFMTLAggregatin\")\n",
    "    # Training phase\n",
    "    for user_id in range(no_users):\n",
    "        print(f\"Training model for User {user_id + 1}\")\n",
    "        user_models = all_models[user_id]\n",
    "        group = user_groups[user_id]\n",
    "\n",
    "        # Train local model for the user's available modalities\n",
    "\n",
    "        train_loss, train_accuracy = train_local_model(\n",
    "            user_modalities[user_id], \n",
    "            user_models, \n",
    "            train_loaders[user_id], \n",
    "            criterion, \n",
    "            optimizers[user_id], \n",
    "            local_epochs, \n",
    "            device\n",
    "        )\n",
    "\n",
    "  \n",
    "\n",
    "        # Store in group-wise metrics\n",
    "        epoch_group_train_losses[group].append(train_loss)\n",
    "        epoch_group_train_accuracies[group].append(train_accuracy)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Validation phase\n",
    "    for user_id in range(no_users):\n",
    "        user_models = all_models[user_id]\n",
    "        val_dict = validate_user_models(\n",
    "            user_id, \n",
    "            user_models, \n",
    "            val_loaders[user_id], \n",
    "            criterion, \n",
    "            user_modalities[user_id], \n",
    "            device\n",
    "        )\n",
    "        group = user_groups[user_id]\n",
    "        epoch_group_val_losses[group].append(val_dict[\"loss\"])\n",
    "        epoch_group_val_accuracies[group].append(val_dict[\"accuracy\"])\n",
    "\n",
    "    # Store final metrics for each group\n",
    "    for group in [1, 2, 3]:\n",
    "        group_train_loss_histories[group].append(np.mean(epoch_group_train_losses[group]))\n",
    "        group_train_accuracy_histories[group].append(np.mean(epoch_group_train_accuracies[group]))\n",
    "        group_val_loss_histories[group].append(np.mean(epoch_group_val_losses[group]))\n",
    "        group_val_accuracy_histories[group].append(np.mean(epoch_group_val_accuracies[group]))\n",
    "\n",
    "    # Print final results for this round\n",
    "    print(f\"---- Global Round {round_num + 1} Metrics ----\")\n",
    "    for group in [1, 2, 3]:\n",
    "        print(f\"  Group {group} - Train Loss: {group_train_loss_histories[group][-1]:.4f}, Train Accuracy: {group_train_accuracy_histories[group][-1]:.4f}\")\n",
    "        print(f\"  Group {group} - Val Loss: {group_val_loss_histories[group][-1]:.4f}, Val Accuracy: {group_val_accuracy_histories[group][-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c9171-1ac2-49ec-bb29-eecec3a3c260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f5b0d-19b9-4050-b245-6d13078d0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class MultiStreamNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiStreamNet, self).__init__()\n",
    "\n",
    "        # Define the streams\n",
    "        self.stream_1 = resnet50(pretrained=True, progress=True, num_classes=64)  # First stream using resnet50\n",
    "        self.stream_2 = NN_beam_pred(num_features=4, num_output=64)  # Second stream using NN_beam_pred\n",
    "        \n",
    "        # Add Batch Normalization layers\n",
    "        self.bn_stream_1 = nn.BatchNorm1d(128)  # Adjust according to the output size of resnet50\n",
    "        self.bn_stream_2 = nn.BatchNorm1d(128)   # Adjust according to the output size of NN_beam_pred\n",
    "\n",
    "        # Combine the two streams and apply Multinomial Logistic Regression\n",
    "        self.fc = MultinomialLogisticRegression(input_size=256, num_classes=64)  # Adjust input_size & num_classes\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Process through stream 1 (resnet50)\n",
    "        out1 = self.stream_1(x1)\n",
    "        out2 = self.bn_stream_1(out1)\n",
    "        print(out1.shape)\n",
    "        print(out2.shape)\n",
    "        \n",
    "        # Process through stream 2 (NN_beam_pred)\n",
    "        out2 = self.stream_2(x2)\n",
    "        out2 = self.bn_stream_2(out2)\n",
    "\n",
    "        # Concatenate the outputs from both streams\n",
    "        out = torch.cat((out1, out2), dim=1)\n",
    "        \n",
    "        # Final classification layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "model = MultiStreamNet().to(device)\n",
    "\n",
    "# Set the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example training loop\n",
    "def train(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            x, y = data  # Assuming inputs1 and inputs2 are from different streams\n",
    "            x[\"images\"], x[\"pos_height\"], y = x[\"images\"].to(device), x[\"pos_height\"].to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(x[\"images\"], x[\"pos_height\"])\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Print average loss per epoch\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Assuming `train_loader` is a DataLoader object containing the training data\n",
    "train(model, train_loaders[0], criterion, optimizer)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6e4d18-b3ff-4a6f-b813-e1db3738d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 6#global_rounds\n",
    "# Convert metrics to numpy arrays for easy manipulation\n",
    "group_train_loss_histories = {k: np.array(v) for k, v in group_train_loss_histories.items()}\n",
    "group_train_accuracy_histories = {k: np.array(v) for k, v in group_train_accuracy_histories.items()}\n",
    "group_val_loss_histories = {k: np.array(v) for k, v in group_val_loss_histories.items()}\n",
    "group_val_accuracy_histories = {k: np.array(v) for k, v in group_val_accuracy_histories.items()}\n",
    "\n",
    "# Handle potential one-dimensional arrays\n",
    "group_train_loss_mean = {k: v.mean(axis=1) if v.ndim > 1 else v for k, v in group_train_loss_histories.items()}\n",
    "group_train_loss_std = {k: v.std(axis=1) if v.ndim > 1 else np.zeros_like(v) for k, v in group_train_loss_histories.items()}\n",
    "group_val_loss_mean = {k: v.mean(axis=1) if v.ndim > 1 else v for k, v in group_val_loss_histories.items()}\n",
    "group_val_loss_std = {k: v.std(axis=1) if v.ndim > 1 else np.zeros_like(v) for k, v in group_val_loss_histories.items()}\n",
    "\n",
    "group_train_acc_mean = {k: v.mean(axis=1) if v.ndim > 1 else v for k, v in group_train_accuracy_histories.items()}\n",
    "group_train_acc_std = {k: v.std(axis=1) if v.ndim > 1 else np.zeros_like(v) for k, v in group_train_accuracy_histories.items()}\n",
    "group_val_acc_mean = {k: v.mean(axis=1) if v.ndim > 1 else v for k, v in group_val_accuracy_histories.items()}\n",
    "group_val_acc_std = {k: v.std(axis=1) if v.ndim > 1 else np.zeros_like(v) for k, v in group_val_accuracy_histories.items()}\n",
    "\n",
    "# Combined Plot for All Modalities\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "for group in [1, 2, 3]:\n",
    "    plt.plot(range(1, num_epochs + 1), group_train_loss_mean[group], label=f\"Group {group} Train Loss\")\n",
    "    plt.fill_between(range(1, num_epochs + 1), \n",
    "                     group_train_loss_mean[group] - group_train_loss_std[group], \n",
    "                     group_train_loss_mean[group] + group_train_loss_std[group], \n",
    "                     alpha=0.2)\n",
    "    plt.plot(range(1, num_epochs + 1), group_val_loss_mean[group], label=f\"Group {group} Validation Loss\", linestyle=\"dashed\")\n",
    "    plt.fill_between(range(1, num_epochs + 1), \n",
    "                     group_val_loss_mean[group] - group_val_loss_std[group], \n",
    "                     group_val_loss_mean[group] + group_val_loss_std[group], \n",
    "                     alpha=0.2)\n",
    "\n",
    "plt.title(\"Loss over Epochs for All Groups\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "for group in [1, 2, 3]:\n",
    "    plt.plot(range(1, num_epochs + 1), group_train_acc_mean[group], label=f\"Group {group} Train Accuracy\")\n",
    "    plt.fill_between(range(1, num_epochs + 1), \n",
    "                     group_train_acc_mean[group] - group_train_acc_std[group], \n",
    "                     group_train_acc_mean[group] + group_train_acc_std[group], \n",
    "                     alpha=0.2)\n",
    "    plt.plot(range(1, num_epochs + 1), group_val_acc_mean[group], label=f\"Group {group} Validation Accuracy\", linestyle=\"dashed\")\n",
    "    plt.fill_between(range(1, num_epochs + 1), \n",
    "                     group_val_acc_mean[group] - group_val_acc_std[group], \n",
    "                     group_val_acc_mean[group] + group_val_acc_std[group], \n",
    "                     alpha=0.2)\n",
    "\n",
    "plt.title(\"Accuracy over Epochs for All Groups\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([0, 1])  # Ensure y-axis is between 0 and 1 for accuracy\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef6bc25-66fc-463b-bf3b-649b95dad7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert numpy arrays to lists for serialization\n",
    "data_to_save = {\n",
    "    \"group_train_loss_mean\": {k: v.tolist() for k, v in group_train_loss_mean.items()},\n",
    "    \"group_train_loss_std\": {k: v.tolist() for k, v in group_train_loss_std.items()},\n",
    "    \"group_val_loss_mean\": {k: v.tolist() for k, v in group_val_loss_mean.items()},\n",
    "    \"group_val_loss_std\": {k: v.tolist() for k, v in group_val_loss_std.items()},\n",
    "    \"group_train_acc_mean\": {k: v.tolist() for k, v in group_train_acc_mean.items()},\n",
    "    \"group_train_acc_std\": {k: v.tolist() for k, v in group_train_acc_std.items()},\n",
    "    \"group_val_acc_mean\": {k: v.tolist() for k, v in group_val_acc_mean.items()},\n",
    "    \"group_val_acc_std\": {k: v.tolist() for k, v in group_val_acc_std.items()}\n",
    "}\n",
    "\n",
    "#with open(\"FMTL_metrics_New_graph_0_2_FL_eye_P.json\", \"w\") as f:\n",
    "#    json.dump(data_to_save, f)\n",
    "print(\"DSGD_metrics.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
